#!/usr/bin/python3
#
# bitcoin-submittx - Stand-alone transaction submitter
#
# Distributed under the MIT/X11 software license, see the accompanying
# file COPYING or http://www.opensource.org/licenses/mit-license.php.
#
# W.J. 2015 - based on "pynode" from https://github.com/jgarzik/pynode.git
#

import struct
import socket,socks
import time
import sys
import threading
from io import BytesIO
from binascii import unhexlify
import argparse

import bitcoin
from bitcoin.core import CTransaction, b2lx
from bitcoin.core.serialize import Hash
from bitcoin.messages import msg_version, msg_inv, msg_ping, msg_verack, msg_pong, msg_tx, messagemap, MsgSerializable, MSG_TX, MSG_BLOCK
from bitcoin.net import CInv

from random import shuffle

# define constants
MIN_PROTO_VERSION = 60001 # Must support BIP0031 (ping/pong)
PROTO_VERSION = 70015 # Supports BIP0031
MY_SUBVERSION = b"/pynode:0.0.1/"



# setup logging

import logging

def addLoggingLevel(levelName, levelNum, methodName=None):      # from https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility/35804945#35804945
    """
    Comprehensively adds a new logging level to the `logging` module and the
    currently configured logging class.

    `levelName` becomes an attribute of the `logging` module with the value
    `levelNum`. `methodName` becomes a convenience method for both `logging`
    itself and the class returned by `logging.getLoggerClass()` (usually just
    `logging.Logger`). If `methodName` is not specified, `levelName.lower()` is
    used.

    To avoid accidental clobberings of existing attributes, this method will
    raise an `AttributeError` if the level name is already an attribute of the
    `logging` module or if the method name is already present 

    Example
    -------
    >>> addLoggingLevel('TRACE', logging.DEBUG - 5)
    >>> logging.getLogger(__name__).setLevel("TRACE")
    >>> logging.getLogger(__name__).trace('that worked')
    >>> logging.trace('so did this')
    >>> logging.TRACE
    5

    """
    if not methodName:
        methodName = levelName.lower()

    if hasattr(logging, levelName):
       raise AttributeError('{} already defined in logging module'.format(levelName))
    if hasattr(logging, methodName):
       raise AttributeError('{} already defined in logging module'.format(methodName))
    if hasattr(logging.getLoggerClass(), methodName):
       raise AttributeError('{} already defined in logger class'.format(methodName))

    # This method was inspired by the answers to Stack Overflow post
    # http://stackoverflow.com/q/2183233/2988730, especially
    # http://stackoverflow.com/a/13638084/2988730
    def logForLevel(self, message, *args, **kwargs):
        if self.isEnabledFor(levelNum):
            self._log(levelNum, message, args, **kwargs)
    def logToRoot(message, *args, **kwargs):
        logging.log(levelNum, message, *args, **kwargs)

    logging.addLevelName(levelNum, levelName)
    setattr(logging, levelName, levelNum)
    setattr(logging.getLoggerClass(), methodName, logForLevel)
    setattr(logging, methodName, logToRoot)

# add more logging levels
addLoggingLevel('INFO2', logging.INFO - 1)
addLoggingLevel('INFO3', logging.INFO2 - 1)
addLoggingLevel('INFO4', logging.INFO3 - 1)
addLoggingLevel('TRACE', logging.DEBUG - 5)

# set the logging format
logging.basicConfig(format='%(levelname)-8s:  %(message)s')

# get level names and their values
LogLevelChoicesDictionary=logging._nameToLevel.copy()           # logging.getLevelNamesMapping() does not exist yet in python 3.10

# remove some duplicate default values and unneeded values to simplify help
LogLevelChoicesDictionary.pop('FATAL')
LogLevelChoicesDictionary.pop('WARN')
LogLevelChoicesDictionary.pop('CRITICAL')
LogLevelChoicesDictionary.pop('NOTSET')

# sort by value and then extract the names
LogLevelChoices=tuple(zip(*sorted(LogLevelChoicesDictionary.items(), key=lambda x: x[1])))[0]





### Utility functions
def recvall(s, n):
    '''Receive n bytes from a socket, or fail'''
    rv = bytearray()
    while n > 0:
        d = s.recv(n)
        if not d:
            raise IOError('Unexpected end of stream')
        rv.extend(d)
        n -= len(d)
    return rv

### Protocol constants
class Command:
    CONNECT = 0x01

class AddressType:
    IPV4 = 0x01
    DOMAINNAME = 0x03
    IPV6 = 0x04



# Node connection #
class NodeConn(threading.Thread):
    def __init__(self, proxy, dstaddr, dstport, peermgr,
                 params, payload):
        threading.Thread.__init__(self)
        self.proxy = proxy
        self.peermgr = peermgr
        self.params = params
        self.recvbuf = b""
        self.ver_send = MIN_PROTO_VERSION
        self.ver_recv = MIN_PROTO_VERSION
        self.last_sent = 0
        self.dst = (dstaddr, dstport)
        self.dstname = '%s:%i' % self.dst
        self.sock = None
        self.stopping=False

        self.transactions = payload

    def run(self):
        logging.info3("connecting to %s" % (self.dstname))

        try:
            # not using `create_connection` because that does not return the `sock` object until connection completes and the `sock.shutdown` and `sock.close` functions then can't work with the `join_all` function.
            # could use a timeout on the socket itself, but this seems a bit more general.
            # also, socks version of `create_connection` doesn't fall back to regular sockets when proxy_type=None, so that makes things less general (but actually still shorter) having to make two seperate calls
            self.sock = socks.socksocket()

            if self.proxy is not None:
                (proxy_addr, proxy_port)=self.proxy
                self.sock.set_proxy(proxy_type=socks.SOCKS5,addr=proxy_addr,port=proxy_port)

            self.sock.connect(self.dst)

        except Exception as e:
            if self.stopping:
                logging.info4("never actually connected to %s:%i (%s)" % (self.dst[0], self.dst[1], e))
            else:
                logging.info4("error connecting to %s:%i (%s)" % (self.dst[0], self.dst[1], e))
                self.handle_close()
            return

        # stuff version msg into sendbuf
        vt = msg_version(PROTO_VERSION)
        vt.nServices = 0
        if self.dst[0].endswith('.onion'):
            vt.addrTo.ip = '0.0.0.0' # XXX encode onion into IP like bitcoind does
        else:
            vt.addrTo.ip = self.dst[0]
        vt.addrTo.port = self.dst[1]
        vt.addrFrom.ip = "0.0.0.0"
        vt.addrFrom.port = 0
        vt.nStartingHeight = 0
        vt.strSubVer = MY_SUBVERSION
        self.send_message(vt)

        logging.info3("connected to " + self.dstname)
        while True:
            try:
                t = self.sock.recv(8192)
                if len(t) <= 0:
                    raise ValueError
            except (IOError, ValueError):
                self.handle_close()
                return
            self.recvbuf += t
            self.got_data()

    def stop(self):
        self.handle_close()

    def handle_close(self):
        self.stopping=True
        if not self.sock:
            return
        logging.info3("closing " + self.dstname)
        self.recvbuf = b""
        try:
            self.sock.shutdown(socket.SHUT_RDWR)
            self.sock.close()
        except:
            pass
        self.sock = None

    def got_data(self):
        while True:
            if len(self.recvbuf) < 4:
                return
            if self.recvbuf[:4] != self.params.MESSAGE_START:
                raise ValueError("got garbage %s" % repr(self.recvbuf))
            # check checksum
            if len(self.recvbuf) < 4 + 12 + 4 + 4:
                return
            command = self.recvbuf[4:4 + 12].split(b"\x00", 1)[0]
            msglen = struct.unpack("<i", self.recvbuf[4 + 12:4 + 12 + 4])[0]
            checksum = self.recvbuf[4 + 12 + 4:4 + 12 + 4 + 4]
            if len(self.recvbuf) < 4 + 12 + 4 + 4 + msglen:
                return
            msg = self.recvbuf[:4 + 12 + 4 + 4 + msglen]
            self.recvbuf = self.recvbuf[4 + 12 + 4 + 4 + msglen:]

            if command in messagemap:
                t = MsgSerializable.stream_deserialize(BytesIO(msg), self.ver_recv)
                self.got_message(t)
            else:
                logging.debug("UNKNOWN COMMAND %s %s" % (command, repr(msg)))

    def send_message(self, message):
        logging.debug("send %s" % repr(message))

        tmsg = message.to_bytes()

        try:
            self.sock.sendall(tmsg)
            self.last_sent = time.time()
        except:
            self.handle_close()

    def start_broadcast(self):
        logging.info3('Starting broadcast')
        msg = msg_inv()
        for h in self.transactions.keys():
            inv = CInv()
            inv.type = MSG_TX
            inv.hash = h
            msg.inv.append(inv)
        self.send_message(msg)

    def got_message(self, message):
        if self.last_sent + 30 * 60 < time.time():
            self.send_message(msg_ping(self.ver_send))

        if message.command == b"reject":
            logging.trace("recv %s" % (repr(message)))
        else:
            logging.trace("recv %s" % repr(message))

        if message.command == b"version":
            self.ver_send = min(PROTO_VERSION, message.nVersion)
            if self.ver_send < MIN_PROTO_VERSION:
                logging.debug(
                    "Obsolete version %d, closing" % (self.ver_send,))
                self.handle_close()
                return

            self.send_message(msg_verack(self.ver_send))

            self.start_broadcast()

        elif message.command == b"verack":
            self.ver_recv = self.ver_send

        elif message.command == b"ping":
            self.send_message(msg_pong(self.ver_send, message.nonce))

        elif message.command == b"getdata":
            self.getdata(message)

        # TODO: count rejects

    def getdata_tx(self, txhash):
        logging.trace('getdata_tx %s' % b2lx(txhash))
        if txhash in self.transactions:
            msg = msg_tx()
            msg.tx = self.transactions[txhash]
            self.send_message(msg)
            self.peermgr.tx_broadcasted(txhash)
        else:
            logging.debug('Peer requested unknown transaction')

    def getdata_block(self, blkhash):
        logging.debug('Peer requested block - this is unsupported')

    def getdata(self, message):
        if len(message.inv) > 50000:
            self.handle_close()
            return
        for inv in message.inv:
            if inv.type == MSG_TX:
                self.getdata_tx(inv.hash)
            elif inv.type == MSG_BLOCK:
                self.getdata_block(inv.hash)

class PeerManager(object):
    def __init__(self, proxy, params, payload):
        self.params = params
        self.peers = []
        self.addrs = {}
        self.tried = {}
        self.payload = payload
        self.stats = {x:0 for x in payload.keys()}
        self.proxy = proxy

    def add(self, host, port):
        self.tried[host] = True
        c = NodeConn(self.proxy, host, port, self, self.params, self.payload)
        self.peers.append(c)
        return c

    def closeall(self):
        for peer in self.peers:
            peer.handle_close()
        self.peers = []

    def tx_broadcasted(self, txhash):
        self.stats[txhash] += 1

# Miscelleneous utility functions #
def join_all(threads, timeout):
    '''
    Join a bunch of threads, with timeout.
    '''
    wait_until = time.time() + timeout
    alive = len(threads)
    while alive:
        alive = 0
        for t in threads:
            next_wait = wait_until - time.time()
            if next_wait <= 0:
                return
            t.join(next_wait)
            alive += t.is_alive()

def parse_host_port(node, default_port):
    '''
    Parse host:port tuple.
    TODO: [::]:12345 IPv6 syntax.
    '''
    (host, _, port) = node.partition(':')
    if port:
        port = int(port)
    else:
        if default_port is None:
            raise ValueError('Must provide port in %s' % node)
        port = default_port
    return (host,port)

# Main program logic #

def parse_args():
    parser = argparse.ArgumentParser(description="Bitcoin Transaction Submission Tool",formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--loglevel', help='Set the log level. Choose WARNING or ERROR to receive no output under normal circumstances. Note: most log levels do not show connection failures as we can many times have a successful broadcast when only a small number of the total nodes that were contacted received the broadcast transaction(s). Use TRACE, DEBUG, or INFO4 to see connection failures.', type=str, choices=LogLevelChoices,default='INFO')
    parser.add_argument('--proxy', '-p', help='SOCKS5 proxy to connect through. Set to `None` to not use a proxy.', default='127.0.0.1:9050')
    parser.add_argument('--timeout', '-t', help='Number of seconds to wait before disconnecting from nodes', type=int, default=15)
    parser.add_argument('--network', help='Network to connect to (mainnet, regtest, testnet). This also determines the default port',default='mainnet')
    parser.add_argument('--nodes', help='List of nodes to connect to, denoted either host or host:port, separated by commas. If None and `nodes-file` is also None, DNS seeds will be used to populate the node list.',default=None)
    parser.add_argument('--nodes-file', '-n', help='Read list of nodes from file (either host or host:port, separated one per line)', default=None)
    parser.add_argument('--max-nodes',help='Max number of nodes to use in the node list. Set to 0 to select all nodes.',type=int,default=35)
    parser.add_argument('--tx-file', '-r', help='Read list of transactions from file (encoded as hex, separated one per line)', default=None)
    parser.add_argument('transactions', help='Serialized transactions (encoded as hex, separated by commas) to broadcast. If None and `tx-file` is also None, you will be prompted to enter (useful if you do not want the transactions stored in your `.bash_history` file).',default=None,nargs='?')
    return parser.parse_args()

def read_lines(filename):
    with open(filename, 'r') as f:
        lines = [line.strip() for line in f]
        lines = [line for line in lines if line]
    return lines


def main():
    args = parse_args()

    logging.getLogger().setLevel(args.loglevel)

    if logging.INFO >= logging.root.level:
        print()

    timeout = args.timeout

    if args.proxy.lower()=='none':
        proxy = None
    else:
        logging.info2("using SOCKS5 proxy "+args.proxy)
        proxy = parse_host_port(args.proxy, None)



    try:
        bitcoin.SelectParams(args.network)
    except:
        logging.error("invalid network %s" % args.network)
        sys.exit(1)
    params = bitcoin.params

    # build transactions list

    # get transactions from the command line
    hex_transactions = args.transactions.split(',') if args.transactions else []
    logging.info2('Read %d transactions from the command line.' % (len(hex_transactions)))

    # get transactions from tx_File
    if args.tx_file:
        lines = read_lines(args.tx_file)
        if verbose:
            logging.info2('Read %d transactions from %s.' % (len(lines), args.tx_file))
        hex_transactions += lines
    else:
        logging.info2('No `tx-file` defined.')

    if len(hex_transactions)==0:
        print()
        UserInput = input('No transactions passed on the command line or in a `tx-file` to broadcast.\n\nPlease enter the serialized transactions (encoded as hex, separated by commas) that you would like to broadcast:\n\n')
        hex_transactions += UserInput.split(',')
        print()

    transactions = {}
    for txdata in hex_transactions:
        txdata = unhexlify(txdata)
        tx = CTransaction.deserialize(txdata)
        transactions[tx.GetTxid()] = tx             # this approach also happens to remove duplicate transactions

    # parse nodes list
    nodes=[]

    if args.nodes is not None:
        nodes += [parse_host_port(node, params.DEFAULT_PORT) for node in args.nodes.split(",")]
        logging.info2('Read %d nodes from the command line' % (len(nodes)))

    if args.nodes_file is not None:
        lines = read_lines(args.nodes_file)
        nodes += [parse_host_port(node, params.DEFAULT_PORT) for node in lines]
        if verbose:
            logging.info2('Read %d nodes from %s' % (len(lines), args.nodes_file))

    if len(nodes)==0:
        logging.info2('no nodes passed on the command line or in a `nodes-file`, looking in DNS seeds')
        seeds=list(map(lambda x: x[1], params.DNS_SEEDS))
        addresses=[]
        for seed in seeds:
            try:
                NewAddresses=list(map( lambda x: x[4][0],socket.getaddrinfo(host=seed, port=0, family=socket.AF_INET, type=socket.SOCK_STREAM)))
                logging.info2('got '+str(len(NewAddresses))+' nodes from '+seed)
                addresses+=NewAddresses
            except:
                logging.info4('can not get any nodes from '+seed)

        logging.info2('got a total of '+str(len(addresses))+ ' nodes from DNS seeds')
        nodes += [parse_host_port(node, params.DEFAULT_PORT) for node in addresses]

    # remove duplicate nodes
    nodes=list(set(nodes))

    # randomize node list so we don't get all nodes from the same DNS seed
    shuffle(nodes)

    if args.max_nodes>0 and args.max_nodes<len(nodes):
        logging.info2('limiting to a maximum of '+str(args.max_nodes)+' nodes')
        nodes=nodes[:args.max_nodes]

    logging.info2('using a total of '+str(len(nodes))+ ' unique nodes from all sources')


    logging.info("Attempting broadcast of %i transactions to %i peers in %i seconds" % (len(transactions), len(nodes), timeout))

    peermgr = PeerManager(proxy, params, transactions)
    threads = []

    # connect to specified remote node(s)
    for host,port in nodes:
        c = peermgr.add(host, port)
        threads.append(c)

    # program main loop
    def start(timeout=None):
        for t in threads:
            t.start()
        try:
            join_all(threads, timeout)
        finally:
            for t in threads:
                t.stop()
            join_all(threads, timeout)

    start(timeout)

    if logging.INFO >= logging.root.level:
        print()
        logging.info('Successful Broadcasts:')
        logging.info('                            TXID                                           Peers')


    total = 0
    for (txhash, count) in peermgr.stats.items():
        logging.info('  %s        %4i' % (b2lx(txhash), count))
        total += count

    if logging.INFO >= logging.root.level:
        print()


    # non-zero exit status if at least one succesful submit
    exit(total == 0)

if __name__ == '__main__':
    main()

